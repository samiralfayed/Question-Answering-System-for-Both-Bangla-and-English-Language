{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2559,"status":"ok","timestamp":1733238981237,"user":{"displayName":"Samir Al Fayed Ifti","userId":"00435113891419916944"},"user_tz":-360},"id":"s3CFM9MFkx5G","outputId":"5e13e3be-7238-4ef9-8135-64b3fe9a9b41"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8By0bpM3lEGd"},"outputs":[],"source":["# Change to the desired directory\n","import os\n","os.chdir('/content/drive/MyDrive/Task-1')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zWe-S7yCpBSV"},"outputs":[],"source":["# Import necessary libraries\n","from datasets import load_dataset\n","import torch\n","from tqdm.auto import tqdm\n","from transformers import BertTokenizerFast, BertForQuestionAnswering"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3690,"status":"ok","timestamp":1733239014917,"user":{"displayName":"Samir Al Fayed Ifti","userId":"00435113891419916944"},"user_tz":-360},"id":"CflHmIFUpKs8","outputId":"de17eaf4-de93-48ff-e949-d624645e7623"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]}],"source":["# Load SQuAD dataset\n","dataset = load_dataset('squad')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPx7olhNprQ1"},"outputs":[],"source":["# Add end indices to answers\n","def add_end_idx(answers, contexts):\n","    for answer, context in zip(answers, contexts):\n","        start_idx = answer['answer_start'][0]\n","        gold_text = answer['text'][0]\n","        end_idx = start_idx + len(gold_text)\n","\n","        if context[start_idx:end_idx] != gold_text:\n","            # Try correcting misalignments\n","            for n in [1, 2]:\n","                if context[start_idx - n:end_idx - n] == gold_text:\n","                    start_idx -= n\n","                    end_idx -= n\n","                    break\n","        answer['answer_end'] = end_idx\n","    return answers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Nehr8X4pt17"},"outputs":[],"source":["# Prepare the data\n","def prep_data(dataset):\n","    contexts = dataset['context']\n","    questions = dataset['question']\n","    answers = add_end_idx(dataset['answers'], contexts)\n","    return {\n","        'context': contexts,\n","        'question': questions,\n","        'answers': answers,\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkaxBMJip066"},"outputs":[],"source":["# Process and shuffle data\n","train_data = prep_data(dataset['train'].shuffle(seed=123).select(range(1000)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dwYNoIDEp2xM"},"outputs":[],"source":["# Tokenize dataset\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","def tokenize_data(data):\n","    encodings = tokenizer(\n","        data['context'], data['question'],\n","        truncation=True, padding='max_length',\n","        max_length=512, return_tensors='pt'\n","    )\n","    start_positions = []\n","    end_positions = []\n","    for i in range(len(data['answers'])):\n","        # Accessing the first element of the answer_start list\n","        start = encodings.char_to_token(i, data['answers'][i]['answer_start'][0])\n","        # Accessing the answer_end, which should be a single integer\n","        end = encodings.char_to_token(i, data['answers'][i]['answer_end'])\n","        if start is None:\n","            start = tokenizer.model_max_length\n","        if end is None:\n","            end = tokenizer.model_max_length\n","\n","        start_positions.append(start)\n","        end_positions.append(end)\n","    # Updating encodings outside the loop\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","    return encodings\n","\n","train_encodings = tokenize_data(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tA_2GiT1p7NT"},"outputs":[],"source":["# Define custom PyTorch dataset\n","class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UwAddqV0p_O-"},"outputs":[],"source":["# Create dataloader\n","train_dataset = SquadDataset(train_encodings)\n","loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PKvOYe6qFsS"},"outputs":[],"source":["# Prepare the dataset and dataloader\n","train_dataset = SquadDataset(train_encodings) # Changed 'train' to 'train_encodings'\n","loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1392,"status":"ok","timestamp":1733239032171,"user":{"displayName":"Samir Al Fayed Ifti","userId":"00435113891419916944"},"user_tz":-360},"id":"qrhUGiaIqJVx","outputId":"766c7467-d62e-4d44-98ef-a2d0deec18c4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# Load the pre-trained BERT model\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1733239032996,"user":{"displayName":"Samir Al Fayed Ifti","userId":"00435113891419916944"},"user_tz":-360},"id":"USjbhdxzAmaq","outputId":"370bb82b-3aee-4bde-e55b-ed8f5c78a125"},"outputs":[{"data":{"text/plain":["BertForQuestionAnswering(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Move model to GPU/CPU\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"kO9yJ1uyEHjk","outputId":"81f66c09-e4cf-4ddb-b3db-dd269b913f80"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-16-4ce035c3feaa>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"]}],"source":["# Simplified training setup\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n","epochs = 1  # Reduced to 1 epoch for quick execution\n","batch_size = 1  # Use a smaller batch size to reduce memory usage\n","\n","# Create a DataLoader with a smaller batch size\n","loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Simplified and memory-efficient training loop\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    for batch in loader:\n","        optimizer.zero_grad()\n","        inputs = {key: val.to(device) for key, val in batch.items()}\n","        outputs = model(**inputs)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(loader):.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":331,"status":"error","timestamp":1733238697651,"user":{"displayName":"Samir Al Fayed Ifti","userId":"00435113891419916944"},"user_tz":-360},"id":"X_mRQUPMqSts","outputId":"5ce5c0cf-1c78-4c1e-cf21-ad270be92d77"},"outputs":[{"ename":"NameError","evalue":"name 'torch' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-48c18ea03df9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define optimizer and training parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["# Define optimizer and training parameters\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n","epochs = 2\n","\n","# Training loop\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    progress_bar = tqdm(loader, desc=f\"Epoch {epoch + 1}\")\n","    for batch in progress_bar:\n","        optimizer.zero_grad()\n","        inputs = {key: val.to(device) for key, val in batch.items()}\n","        outputs = model(**inputs)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        progress_bar.set_postfix(loss=total_loss / len(loader))"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuZnz5Njd0q5vnUsNPmrFd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}